{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f242068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad72aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source  Target\n",
      "0       0       9\n",
      "1       0     268\n",
      "2       0    1845\n",
      "3       0    1940\n",
      "4       0    2338\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28124 entries, 0 to 28123\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Source  28124 non-null  int64\n",
      " 1   Target  28124 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 439.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV\n",
    "df = pd.read_csv(\"twitter_higgs_TOP.csv\")\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø£ÙˆÙ„ 5 Ø£Ø³Ø·Ø±\n",
    "print(df.head())\n",
    "\n",
    "# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø© Ø¹Ù† Ø§Ù„Ù…Ù„Ù\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b35b07",
   "metadata": {},
   "source": [
    "# 1. Ø¬Ø²Ø¡ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Preparation & Adjacency List)\n",
    "\n",
    "Ù‡Ù†Ø§ Ù†Ù‚Ø±Ø£ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ†Ø¨Ù†ÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…. Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©: Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ø¶Ø§ÙØ© reverse_adj Ù„Ø£Ù†Ù‡Ø§ Ø§Ù„Ø­Ù„ Ø§Ù„ÙˆØ­ÙŠØ¯ Ù„Ø¬Ø¹Ù„ PageRank ÙŠØ¹Ù…Ù„ Ø¨ÙƒÙØ§Ø¡Ø©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae3a1fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Data Preparation & Adjacency List ---\n",
      "Total Nodes: 998\n",
      "Total Edges: 28124\n",
      "âœ… Data Prepared and Adjacency Lists built (Normal & Reverse).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "print(\"--- 1. Data Preparation & Adjacency List ---\")\n",
    "\n",
    "# Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù†Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© 5000 Ù„Ù„Ø³Ø±Ø¹Ø© ÙÙŠ Ø§Ù„ØªØ¬Ø±Ø¨Ø©ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø²Ø§Ù„Ø© nrows Ù„Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„)\n",
    "df = pd.read_csv(\"twitter_higgs_TOP.csv\") \n",
    "\n",
    "# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù‚ÙˆØ§Ø¦Ù…\n",
    "adj = defaultdict(list)      # Ù„Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† Ø§Ù„Ø¹Ù‚Ø¯Ø© (Out-neighbors)\n",
    "reverse_adj = defaultdict(list) # Ù„Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ø¹Ù‚Ø¯Ø© (In-neighbors) - Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ Ù„Ù€ PageRank\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    source = int(row['Source'])\n",
    "    target = int(row['Target'])\n",
    "    \n",
    "    adj[source].append(target)\n",
    "    reverse_adj[target].append(source)\n",
    "\n",
    "# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù‚Ø¯ ÙÙŠ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ (Ø­ØªÙ‰ Ù„Ùˆ Ù„Ù… ØªÙƒÙ† Ù„Ø¯ÙŠÙ‡Ø§ Ø±ÙˆØ§Ø¨Ø· Ø®Ø§Ø±Ø¬Ø©)\n",
    "all_nodes = set(adj.keys()).union(set(reverse_adj.keys()))\n",
    "for node in all_nodes:\n",
    "    if node not in adj: adj[node] = []\n",
    "    if node not in reverse_adj: reverse_adj[node] = []\n",
    "\n",
    "nodes = list(all_nodes)\n",
    "N = len(nodes)\n",
    "\n",
    "print(f\"Total Nodes: {N}\")\n",
    "print(f\"Total Edges: {len(df)}\")\n",
    "print(\"âœ… Data Prepared and Adjacency Lists built (Normal & Reverse).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4eb4b1f",
   "metadata": {},
   "source": [
    "# 2. Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„Ù…Ø³Ø§ÙØ© (Distance) ÙˆØ§Ù„Ø§ØªØµØ§Ù„ (Connectivity)\n",
    "Ù‡Ù†Ø§ Ø·Ø¨Ù‚Ù†Ø§ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Dijkstra ÙŠØ¯ÙˆÙŠÙ‹Ø§ (Ø¨Ø¯ÙˆÙ† heapq) ÙƒÙ…Ø§ Ù‡Ùˆ Ù…Ø·Ù„ÙˆØ¨ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† BFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6595d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Distance & Connectivity (Dijkstra) ---\n",
      "Dijkstra from node 0:\n",
      " - Reachable nodes: 991\n",
      " - Max distance (diameter sample): 8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. Distance & Connectivity (Dijkstra) ---\")\n",
    "\n",
    "def dijkstra_custom(start_node, adj):\n",
    "    \"\"\"\n",
    "    Ø­Ø³Ø§Ø¨ Ø£Ù‚ØµØ± Ù…Ø³Ø§Ø± Ù…Ù† Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Dijkstra.\n",
    "    Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¨Ù…Ø§ Ø£Ù† Ø§Ù„Ø±Ø³Ù… ØºÙŠØ± Ù…Ø±Ø¬Ø­ (Unweighted)ØŒ ÙØ¥Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø³Ù„ÙˆÙƒÙ‡Ø§ ÙŠØ´Ø¨Ù‡ BFS\n",
    "    ÙˆÙ„ÙƒÙ†Ù†Ø§ Ù†ÙƒØªØ¨Ù‡Ø§ Ø¨ØµÙŠØºØ© Dijkstra Ù„ØªÙ„Ø¨ÙŠØ© Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ÙƒÙˆØ±Ø³ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©.\n",
    "    \"\"\"\n",
    "    distances = {node: float('infinity') for node in adj}\n",
    "    distances[start_node] = 0\n",
    "    unvisited = list(adj.keys())\n",
    "    \n",
    "    while unvisited:\n",
    "        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø°Ø§Øª Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø£ØµØºØ± (Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… heapq)\n",
    "        # Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù‡ÙŠ Ù…Ø§ ÙŠØ¬Ø¹Ù„Ù‡Ø§ O(N^2) ÙˆÙ‡Ùˆ Ù…Ù‚Ø¨ÙˆÙ„ Ù„Ù„ÙƒÙˆØ¯ Ø§Ù„ÙŠØ¯ÙˆÙŠ Ø¨Ø¯ÙˆÙ† Ù…ÙƒØªØ¨Ø§Øª\n",
    "        current_node = min(unvisited, key=lambda node: distances[node])\n",
    "        \n",
    "        current_dist = distances[current_node]\n",
    "        \n",
    "        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø£ØµØºØ± Ù…Ø³Ø§ÙØ© Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ø§Ù†Ù‡Ø§Ø¦ÙŠØ©ØŒ ÙÙ…Ø¹Ù†Ù‰ Ø°Ù„Ùƒ Ø£Ù† Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© ØºÙŠØ± Ù…ØªØµÙ„Ø©\n",
    "        if current_dist == float('infinity'):\n",
    "            break\n",
    "            \n",
    "        for neighbor in adj[current_node]:\n",
    "            distance = current_dist + 1 # Ø§Ù„ÙˆØ²Ù† 1 Ù„Ø£Ù† Ø§Ù„Ø±Ø³Ù… ØºÙŠØ± Ù…Ø±Ø¬Ø­\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                \n",
    "        unvisited.remove(current_node)\n",
    "        \n",
    "    return distances\n",
    "\n",
    "# ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©\n",
    "sample_node = nodes[0]\n",
    "distances = dijkstra_custom(sample_node, adj)\n",
    "reachable = [d for d in distances.values() if d < float('infinity')]\n",
    "print(f\"Dijkstra from node {sample_node}:\")\n",
    "print(f\" - Reachable nodes: {len(reachable)}\")\n",
    "print(f\" - Max distance (diameter sample): {max(reachable) if reachable else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a4aaeb",
   "metadata": {},
   "source": [
    "# 3. Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (Centrality)\n",
    "ØªÙ… ØªØµØ­ÙŠØ­ PageRank Ù„ÙŠØµØ¨Ø­ Ø³Ø±ÙŠØ¹Ù‹Ø§ØŒ ÙˆØªÙ… ØªØ¹Ø¯ÙŠÙ„ ØµÙŠØºØ© Closeness Ù„ØªÙƒÙˆÙ† Option II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "556fa046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Centrality Measures ---\n",
      "Top Degree: [(40588, 0.1715145436308927), (49428, 0.1675025075225677), (49926, 0.16148445336008024)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top PageRank: [(1344, 0.010755765522412999), (0, 0.010625126564964046), (4920, 0.010623247758641841)]\n",
      "Top Closeness (Sample): [(12, 0.37842339927966767), (16440, 0.3704535947066472), (41, 0.3610836174211785)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 3. Centrality Measures ---\")\n",
    "\n",
    "# Ø£. Degree Centrality (ÙƒÙ…Ø§ Ù‡ÙŠØŒ ØµØ­ÙŠØ­Ø©)\n",
    "def degree_centrality_custom(adj, total_nodes):\n",
    "    degree_scores = {}\n",
    "    for node in adj:\n",
    "        degree_scores[node] = len(adj[node]) / (total_nodes - 1)\n",
    "    return degree_scores\n",
    "\n",
    "degree_scores = degree_centrality_custom(adj, N)\n",
    "print(f\"Top Degree: {sorted(degree_scores.items(), key=lambda x: x[1], reverse=True)[:3]}\")\n",
    "\n",
    "# Ø¨. PageRank (ØªÙ… Ø§Ù„ØªØ­Ø³ÙŠÙ†: Ø§Ø³ØªØ®Ø¯Ø§Ù… reverse_adj)\n",
    "def pagerank_custom(adj, reverse_adj, damping_factor=0.85, iterations=20):\n",
    "    nodes = list(adj.keys())\n",
    "    N = len(nodes)\n",
    "    pr = {node: 1/N for node in nodes} # Initial values\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        new_pr = {}\n",
    "        for node in nodes:\n",
    "            rank_sum = 0\n",
    "            # Ø§Ù„ØªØ­Ø³ÙŠÙ†: Ù†Ø³ØªØ®Ø¯Ù… reverse_adj Ù„Ù„ÙˆØµÙˆÙ„ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ø¹Ù‚Ø¯ Ø§Ù„ØªÙŠ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ node\n",
    "            # Ù‡Ø°Ø§ ÙŠØ­ÙˆÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ù…Ù† O(N^2) Ø¥Ù„Ù‰ O(E)\n",
    "            for in_neighbor in reverse_adj[node]:\n",
    "                rank_sum += pr[in_neighbor] / len(adj[in_neighbor])\n",
    "            \n",
    "            new_pr[node] = (1 - damping_factor) / N + damping_factor * rank_sum\n",
    "        pr = new_pr\n",
    "        \n",
    "    return pr\n",
    "\n",
    "pr_scores = pagerank_custom(adj, reverse_adj)\n",
    "print(f\"Top PageRank: {sorted(pr_scores.items(), key=lambda x: x[1], reverse=True)[:3]}\")\n",
    "\n",
    "# Ø¬. Closeness Centrality (ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„ØµÙŠØºØ©: Option II)\n",
    "def closeness_centrality_custom(adj, dijkstra_func, sample_nodes=None):\n",
    "    closeness = {}\n",
    "    # Ù†Ø®ØªØ§Ø± Ø¹ÙŠÙ†Ø© Ù„Ø£Ù† Ø­Ø³Ø§Ø¨Ù‡Ø§ Ù„Ù„Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙ„Ù Ø¬Ø¯Ø§Ù‹\n",
    "    if sample_nodes is None:\n",
    "        sample_nodes = list(adj.keys())[:100] \n",
    "        \n",
    "    for node in sample_nodes:\n",
    "        distances = dijkstra_func(node, adj)\n",
    "        \n",
    "        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ù…ØªÙˆØµÙ„Ø© ÙÙ‚Ø·\n",
    "        reachable_dists = {k: v for k, v in distances.items() if v < float('infinity')}\n",
    "        reachable_nodes_count = len(reachable_dists)\n",
    "        \n",
    "        if reachable_nodes_count > 1:\n",
    "            sum_distances = sum(reachable_dists.values())\n",
    "            # Ø§Ù„ØµÙŠØºØ© Ø§Ù„Ù…ØµØ­Ø­Ø© Ù„Ù„Ø£Ø´Ø¨Ø§Ù‡ ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø© (Option II):\n",
    "            # (|R(v)| / (N-1)) * (|R(v)| / sum_dist)\n",
    "            score = (reachable_nodes_count / (N - 1)) * (reachable_nodes_count / sum_distances)\n",
    "            closeness[node] = score\n",
    "        else:\n",
    "            closeness[node] = 0.0\n",
    "            \n",
    "    return closeness\n",
    "\n",
    "close_scores = closeness_centrality_custom(adj, dijkstra_custom, sample_nodes=nodes[:20])\n",
    "print(f\"Top Closeness (Sample): {sorted(close_scores.items(), key=lambda x: x[1], reverse=True)[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8326666",
   "metadata": {},
   "source": [
    "# 4. Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù„Ø«: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª (Community Detection)\n",
    "ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù€ Random Logic Ø¨Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© AGNES (Hierarchical Clustering). Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© ØªØ¨Ø¯Ø£ Ø¨ÙƒÙ„ Ø¹Ù‚Ø¯Ø© ÙƒÙ…Ø¬ØªÙ…Ø¹ Ù…Ù†ÙØµÙ„ØŒ Ø«Ù… ØªÙ‚ÙˆÙ… Ø¨Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª Ø§Ù„Ù…ØªØµÙ„Ø© Ø¨Ø£Ù‚ÙˆÙ‰ Ø±ÙˆØ§Ø¨Ø· ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§. Ù‡ÙŠ Ø·Ø±ÙŠÙ‚Ø© Ù‚ÙˆÙŠØ©ØŒ Ø³Ù‡Ù„Ø© Ø§Ù„ØªÙ†ÙÙŠØ° ÙŠØ¯ÙˆÙŠÙ‹Ø§ØŒ ÙˆÙ…Ù‚Ø¨ÙˆÙ„Ø© Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠÙ‹Ø§ ÙƒØ¨Ø¯ÙŠÙ„ Ù„Ù€ Girwan-Newman Ø§Ù„Ù…Ø¹Ù‚Ø¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b87e99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Community Detection (AGNES - Hierarchical) ---\n",
      "Starting clustering with 998 nodes...\n",
      "âœ… Found 3 communities.\n",
      "Community 1: 996 nodes (Sample nodes: [0, 9, 12, 22, 41]...)\n",
      "Community 2: 1 nodes (Sample nodes: [391313]...)\n",
      "Community 3: 1 nodes (Sample nodes: [278161]...)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4. Community Detection (AGNES - Hierarchical) ---\")\n",
    "\n",
    "def agnes_community_detection(adj, n_clusters=2):\n",
    "    \"\"\"\n",
    "    Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© AGNES Ù…Ø¨Ø³Ø·Ø©.\n",
    "    ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Bottom-Up:\n",
    "    1. ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©ØŒ ÙƒÙ„ Ø¹Ù‚Ø¯Ø© Ù‡ÙŠ Ù…Ø¬ØªÙ…Ø¹.\n",
    "    2. Ù†Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ù Ø¨ÙŠÙ† ÙƒÙ„ Ù…Ø¬ØªÙ…Ø¹ ÙˆØ¢Ø®Ø±.\n",
    "    3. Ù†Ø¯Ù…Ø¬ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹ÙŠÙ† Ø§Ù„Ù„Ø°ÙŠÙ† Ø¨ÙŠÙ†Ù‡Ù…Ø§ Ø£ÙƒØ¨Ø± Ø¹Ø¯Ø¯ Ù…Ù† Ø§Ù„Ø­ÙˆØ§Ù.\n",
    "    4. Ù†ÙƒØ±Ø± Ø­ØªÙ‰ Ù†ØµÙ„ Ø¥Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨.\n",
    "    \"\"\"\n",
    "    # 1. Initialization: ÙƒÙ„ Ø¹Ù‚Ø¯Ø© ÙÙŠ Ù…Ø¬ØªÙ…Ø¹ Ø®Ø§Øµ Ø¨Ù‡Ø§ (Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù€ ID Ù†ÙØ³Ù‡ ÙƒÙ€ Community ID)\n",
    "    communities = {node: i for i, node in enumerate(adj.keys())}\n",
    "    \n",
    "    current_num_communities = len(communities)\n",
    "    \n",
    "    print(f\"Starting clustering with {current_num_communities} nodes...\")\n",
    "    \n",
    "    # 2. Loop Ø­ØªÙ‰ Ù†ØµÙ„ Ù„Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª\n",
    "    while current_num_communities > n_clusters:\n",
    "        # Ø­Ø³Ø§Ø¨ ØªØ±Ø§Ø¨Ø· Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª (Inter-community edge count)\n",
    "        # Ù†Ø³ØªØ®Ø¯Ù… Ù…ØµÙÙˆÙØ© Ù…Ø¤Ù‚ØªØ© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙˆØ© Ø¨ÙŠÙ† ÙƒÙ„ Ø²ÙˆØ¬ Ù…Ù† Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª\n",
    "        edge_counts = defaultdict(int)\n",
    "        \n",
    "        for u in adj:\n",
    "            for v in adj[u]:\n",
    "                comm_u = communities[u]\n",
    "                comm_v = communities[v]\n",
    "                \n",
    "                if comm_u != comm_v:\n",
    "                    # Ù†Ø±ØªØ¨ Ø§Ù„Ø²ÙˆØ¬ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…ÙˆØ­Ø¯ (a,b) == (b,a)\n",
    "                    pair = tuple(sorted((comm_u, comm_v)))\n",
    "                    edge_counts[pair] += 1\n",
    "        \n",
    "        if not edge_counts:\n",
    "            print(\"Stopped: No more edges to merge (Graph is fully disconnected).\")\n",
    "            break\n",
    "            \n",
    "        # 3. Ø¥ÙŠØ¬Ø§Ø¯ Ø£Ù‚ÙˆÙ‰ Ù…Ø¬ØªÙ…Ø¹ÙŠÙ† (Ø£Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø­ÙˆØ§Ù)\n",
    "        (comm1, comm2), max_edges = max(edge_counts.items(), key=lambda item: item[1])\n",
    "        \n",
    "        # 4. Merge: Ø¯Ù…Ø¬ comm2 Ø¯Ø§Ø®Ù„ comm1\n",
    "        for node in communities:\n",
    "            if communities[node] == comm2:\n",
    "                communities[node] = comm1\n",
    "        \n",
    "        current_num_communities -= 1\n",
    "        # print(f\"Merged Community {comm2} into {comm1} (Strength: {max_edges})\")\n",
    "\n",
    "    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬\n",
    "    clusters = defaultdict(list)\n",
    "    for node, comm_id in communities.items():\n",
    "        clusters[comm_id].append(node)\n",
    "        \n",
    "    return list(clusters.values())\n",
    "\n",
    "# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø«Ù„Ø§Ù‹ 3 Ù…Ø¬ØªÙ…Ø¹Ø§Øª\n",
    "found_communities = agnes_community_detection(adj, n_clusters=3)\n",
    "\n",
    "print(f\"âœ… Found {len(found_communities)} communities.\")\n",
    "for i, comm in enumerate(found_communities):\n",
    "    print(f\"Community {i+1}: {len(comm)} nodes (Sample nodes: {comm[:5]}...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52eb854",
   "metadata": {},
   "source": [
    "valid with netwarm X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aebbf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "161e9fff",
   "metadata": {},
   "source": [
    "# part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac94e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5. Validation using NetworkX ---\n",
      "\n",
      "=================================================================\n",
      "VALIDATING DEGREE CENTRALITY\n",
      "=================================================================\n",
      "\n",
      "ğŸ” Comparison for: Degree Centrality\n",
      "Custom Implementation          | NetworkX (Library)            \n",
      "-----------------------------------------------------------------\n",
      "Node 40588: 0.171515           | Node 56151: 0.273821\n",
      "Node 49428: 0.167503           | Node 7200: 0.272818\n",
      "Node 49926: 0.161484           | Node 7669: 0.264794\n",
      "Node 107489: 0.156469           | Node 6098: 0.248746\n",
      "Node 2703: 0.145436           | Node 40588: 0.233701\n",
      "âš ï¸  Difference: Top nodes differ.\n",
      "   Your top node: 40588 (0.171515)\n",
      "   NetworkX top: 56151 (0.273821)\n",
      "\n",
      "=================================================================\n",
      "VALIDATING PAGERANK\n",
      "=================================================================\n",
      "\n",
      "ğŸ” Comparison for: PageRank\n",
      "Custom Implementation          | NetworkX (Library)            \n",
      "-----------------------------------------------------------------\n",
      "Node 1344: 0.010756           | Node 1344: 0.012154\n",
      "Node 0: 0.010625           | Node 0: 0.012056\n",
      "Node 4920: 0.010623           | Node 4920: 0.011240\n",
      "Node 48706: 0.010024           | Node 48706: 0.010626\n",
      "Node 703: 0.008704           | Node 703: 0.009841\n",
      "âœ… Match: Top node is identical.\n",
      "\n",
      "=================================================================\n",
      "VALIDATING CLOSENESS CENTRALITY\n",
      "=================================================================\n",
      "\n",
      "Custom closeness scores available: 20\n",
      "NetworkX closeness scores: 998\n",
      "\n",
      "ğŸ“Š Top 10 from Custom Implementation:\n",
      "  Node 12: 0.378423\n",
      "  Node 16440: 0.370454\n",
      "  Node 41: 0.361084\n",
      "  Node 22: 0.357415\n",
      "  Node 94214: 0.357285\n",
      "  Node 4154: 0.355737\n",
      "  Node 9: 0.354330\n",
      "  Node 192582: 0.351548\n",
      "  Node 188502: 0.350297\n",
      "  Node 294932: 0.345627\n",
      "\n",
      "ğŸ“Š Top 10 from NetworkX:\n",
      "  Node 1828: 0.491368\n",
      "  Node 6098: 0.479953\n",
      "  Node 703: 0.477934\n",
      "  Node 2548: 0.476681\n",
      "  Node 5152: 0.475186\n",
      "  Node 6059: 0.471001\n",
      "  Node 2853: 0.467368\n",
      "  Node 22116: 0.456112\n",
      "  Node 1940: 0.449570\n",
      "  Node 28423: 0.446479\n",
      "\n",
      "ğŸ” Comparison for: Closeness Centrality\n",
      "Custom Implementation          | NetworkX (Library)            \n",
      "-----------------------------------------------------------------\n",
      "Node 12: 0.378423           | Node 1828: 0.491368\n",
      "Node 16440: 0.370454           | Node 6098: 0.479953\n",
      "Node 41: 0.361084           | Node 703: 0.477934\n",
      "Node 22: 0.357415           | Node 2548: 0.476681\n",
      "Node 94214: 0.357285           | Node 5152: 0.475186\n",
      "âš ï¸  Difference: Top nodes differ.\n",
      "   Your top node: 12 (0.378423)\n",
      "   NetworkX top: 1828 (0.491368)\n",
      "\n",
      "ğŸ” Diagnostic Information:\n",
      "  Total nodes in graph: 998\n",
      "  Total edges in graph: 28124\n",
      "  Is graph strongly connected: False\n",
      "  Number of strongly connected components: 51\n",
      "\n",
      "=================================================================\n",
      "VALIDATING COMMUNITY DETECTION\n",
      "=================================================================\n",
      "\n",
      "ğŸ” Comparison for: Community Detection\n",
      "Note: Community algorithms yield different results based on logic.\n",
      "We check if NetworkX also finds multiple communities.\n",
      "\n",
      "Custom AGNES found: 3 communities.\n",
      "NetworkX Label Propagation found: 4 communities.\n",
      "\n",
      "Custom community sizes:\n",
      "  Community 1: 996 nodes\n",
      "  Community 2: 1 nodes\n",
      "  Community 3: 1 nodes\n",
      "\n",
      "NetworkX community sizes:\n",
      "  Community 1: 743 nodes\n",
      "  Community 2: 245 nodes\n",
      "  Community 3: 8 nodes\n",
      "  Community 4: 2 nodes\n",
      "\n",
      "âœ… Both algorithms agree the graph is divisible into communities.\n",
      "\n",
      "=================================================================\n",
      "Validation Process Completed.\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "print(\"--- 5. Validation using NetworkX ---\")\n",
    "\n",
    "# Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† df (Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø°ÙŠ ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) Ù…ØªØ§Ø­Ø§Ù‹ Ù…Ù† Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„\n",
    "# Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ØªØ§Ø­Ø§Ù‹ØŒ Ø£Ø¹Ø¯ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ØµØºØ±:\n",
    "try:\n",
    "    df.head() \n",
    "except NameError:\n",
    "    print(\"Reloading data for validation...\")\n",
    "    df = pd.read_csv(\"twitter_higgs_TOP.csv\")\n",
    "\n",
    "# 1. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NetworkX\n",
    "G = nx.from_pandas_edgelist(df, 'Source', 'Target', create_using=nx.DiGraph())\n",
    "\n",
    "# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Top 5 Nodes)\n",
    "def compare_metrics(custom_dict, nx_dict, metric_name):\n",
    "    print(f\"\\nğŸ” Comparison for: {metric_name}\")\n",
    "    \n",
    "    # ØªØµÙÙŠØ© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ØµÙØ±ÙŠØ© Ø£Ùˆ ØºÙŠØ± Ø§Ù„ØµØ­ÙŠØ­Ø©\n",
    "    custom_filtered = {k: v for k, v in custom_dict.items() if v > 0}\n",
    "    nx_filtered = {k: v for k, v in nx_dict.items() if v > 0}\n",
    "    \n",
    "    # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙŠØ¯ÙˆÙŠØ©\n",
    "    custom_top = sorted(custom_filtered.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    # ØªØ±ØªÙŠØ¨ Ù†ØªØ§Ø¦Ø¬ NetworkX\n",
    "    nx_top = sorted(nx_filtered.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    \n",
    "    print(f\"{'Custom Implementation':<30} | {'NetworkX (Library)':<30}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    min_len = min(len(custom_top), len(nx_top))\n",
    "    for i in range(min_len):\n",
    "        c_node, c_val = custom_top[i]\n",
    "        n_node, n_val = nx_top[i]\n",
    "        print(f\"Node {c_node}: {c_val:.6f}           | Node {n_node}: {n_val:.6f}\")\n",
    "    \n",
    "    # ÙØ­Øµ Ø¨Ø³ÙŠØ·: Ù‡Ù„ Ø§Ù„Ø¹Ù‚Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù‡ÙŠ Ù†ÙØ³Ù‡Ø§ØŸ\n",
    "    if len(custom_top) > 0 and len(nx_top) > 0:\n",
    "        if custom_top[0][0] == nx_top[0][0]:\n",
    "            print(\"âœ… Match: Top node is identical.\")\n",
    "        else:\n",
    "            print(\"âš ï¸  Difference: Top nodes differ.\")\n",
    "            print(f\"   Your top node: {custom_top[0][0]} ({custom_top[0][1]:.6f})\")\n",
    "            print(f\"   NetworkX top: {nx_top[0][0]} ({nx_top[0][1]:.6f})\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Ø£. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Degree Centrality\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"VALIDATING DEGREE CENTRALITY\")\n",
    "print(\"=\"*65)\n",
    "nx_degree = nx.degree_centrality(G)\n",
    "compare_metrics(degree_scores, nx_degree, \"Degree Centrality\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Ø¨. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† PageRank\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"VALIDATING PAGERANK\")\n",
    "print(\"=\"*65)\n",
    "# NetworkX ÙŠØ³ØªØ®Ø¯Ù… Ù†ÙØ³ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ®Ù…ÙŠØ¯ (alpha=0.85)\n",
    "nx_pagerank = nx.pagerank(G, alpha=0.85, max_iter=100, tol=1e-6)\n",
    "compare_metrics(pr_scores, nx_pagerank, \"PageRank\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Ø¬. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Closeness Centrality\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"VALIDATING CLOSENESS CENTRALITY\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "# Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©: Closeness Centrality ÙÙŠ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© ÙŠØ­Ø³Ø¨ Ø¹Ù„Ù‰ Ø£Ø³Ø§Ø³\n",
    "# Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„ØµØ§Ø¯Ø±Ø© (outgoing paths) Ù…Ù† ÙƒÙ„ Ø¹Ù‚Ø¯Ø©\n",
    "# Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ Ø¹Ù‚Ø¯ ØºÙŠØ± Ù…ØªØµÙ„Ø©ØŒ NetworkX ÙŠØ³ØªØ®Ø¯Ù… wf_improved=True\n",
    "# Ù„Ø­Ø³Ø§Ø¨ normalized closeness\n",
    "\n",
    "# Ø­Ø³Ø§Ø¨ Closeness Ù…Ù† NetworkX\n",
    "nx_closeness = nx.closeness_centrality(G, wf_improved=True)\n",
    "\n",
    "# Ø¥Ø°Ø§ ÙƒØ§Ù† close_scores ÙØ§Ø±ØºØ§Ù‹ Ø£Ùˆ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ø®Ø§Ø·Ø¦Ø©ØŒ Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ù…Ø´ÙƒÙ„Ø©\n",
    "# ÙÙŠ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©. Ø¯Ø¹Ù†Ø§ Ù†ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£ÙˆÙ„Ø§Ù‹:\n",
    "print(f\"\\nCustom closeness scores available: {len(close_scores)}\")\n",
    "print(f\"NetworkX closeness scores: {len(nx_closeness)}\")\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø£Ø¹Ù„Ù‰ 10 Ù‚ÙŠÙ… Ù…Ù† ÙƒÙ„ ÙˆØ§Ø­Ø¯ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
    "print(\"\\nğŸ“Š Top 10 from Custom Implementation:\")\n",
    "custom_sorted = sorted(close_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for node, score in custom_sorted:\n",
    "    print(f\"  Node {node}: {score:.6f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Top 10 from NetworkX:\")\n",
    "nx_sorted = sorted(nx_closeness.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "for node, score in nx_sorted:\n",
    "    print(f\"  Node {node}: {score:.6f}\")\n",
    "\n",
    "# Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©\n",
    "compare_metrics(close_scores, nx_closeness, \"Closeness Centrality\")\n",
    "\n",
    "# ØªØ´Ø®ÙŠØµ Ø¥Ø¶Ø§ÙÙŠ\n",
    "print(\"\\nğŸ” Diagnostic Information:\")\n",
    "print(f\"  Total nodes in graph: {G.number_of_nodes()}\")\n",
    "print(f\"  Total edges in graph: {G.number_of_edges()}\")\n",
    "print(f\"  Is graph strongly connected: {nx.is_strongly_connected(G)}\")\n",
    "print(f\"  Number of strongly connected components: {nx.number_strongly_connected_components(G)}\")\n",
    "\n",
    "# Ù…Ù„Ø§Ø­Ø¸Ø©: ÙÙŠ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ÙˆØ¬Ù‡Ø© ØºÙŠØ± Ø§Ù„Ù…ØªØµÙ„Ø© Ø¨Ù‚ÙˆØ©ØŒ \n",
    "# Ù‚ÙŠÙ… Closeness Ø³ØªÙƒÙˆÙ† ØµØºÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (Ù‚Ø±ÙŠØ¨Ø© Ù…Ù† Ø§Ù„ØµÙØ±)\n",
    "# Ù„Ø£Ù† Ù…Ø¹Ø¸Ù… Ø§Ù„Ø¹Ù‚Ø¯ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡Ø§ Ù…Ù† Ø¨Ø¹Ø¶Ù‡Ø§ Ø§Ù„Ø¨Ø¹Ø¶\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Ø¯. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Communities (Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ÙˆØ¹ÙŠØ©)\n",
    "# ============================\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"VALIDATING COMMUNITY DETECTION\")\n",
    "print(\"=\"*65)\n",
    "print(\"\\nğŸ” Comparison for: Community Detection\")\n",
    "print(\"Note: Community algorithms yield different results based on logic.\")\n",
    "print(\"We check if NetworkX also finds multiple communities.\")\n",
    "\n",
    "# Ù†Ø³ØªØ®Ø¯Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© Label Propagation Ù…Ù† NetworkX ÙƒÙ…Ø±Ø¬Ø¹ Ø³Ø±ÙŠØ¹\n",
    "# Ù…Ù„Ø§Ø­Ø¸Ø©: Label Propagation ØªØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø³ÙˆÙ… ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬Ù‡Ø©\n",
    "G_undirected = G.to_undirected()\n",
    "comms = list(nx.community.label_propagation_communities(G_undirected))\n",
    "\n",
    "print(f\"\\nCustom AGNES found: {len(found_communities)} communities.\")\n",
    "print(f\"NetworkX Label Propagation found: {len(comms)} communities.\")\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ù…Ø¬ØªÙ…Ø¹Ø§Øª\n",
    "print(\"\\nCustom community sizes:\")\n",
    "for i, comm in enumerate(found_communities, 1):\n",
    "    print(f\"  Community {i}: {len(comm)} nodes\")\n",
    "\n",
    "print(\"\\nNetworkX community sizes:\")\n",
    "for i, comm in enumerate(comms, 1):\n",
    "    print(f\"  Community {i}: {len(comm)} nodes\")\n",
    "\n",
    "if len(found_communities) > 1 and len(comms) > 1:\n",
    "    print(\"\\nâœ… Both algorithms agree the graph is divisible into communities.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  One algorithm suggests a single giant community.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"Validation Process Completed.\")\n",
    "print(\"=\"*65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
